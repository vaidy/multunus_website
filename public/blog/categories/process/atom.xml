<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Process | Multunus]]></title>
  <link href="http://www.multunus.com/blog/categories/process/atom.xml" rel="self"/>
  <link href="http://www.multunus.com/"/>
  <updated>2013-03-10T14:24:04+05:30</updated>
  <id>http://www.multunus.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[How we chose our Kanban Tool]]></title>
    <link href="http://www.multunus.com/2013/03/how-we-chose-our-kanban-tool/"/>
    <updated>2013-03-09T22:39:00+05:30</updated>
    <id>http://www.multunus.com/2013/03/how-we-chose-our-kanban-tool</id>
    <content type="html"><![CDATA[<p>We've been using <a href="http://www.pivotaltracker.com/">Pivotal Tracker</a> as our Project Management Tool so far, but realized that it would not work as a Kanban Tool as the implementation is entirely different. I am not going to talk about "Why Kanban", because there are many articles and books which talks about the same. But I am talking about how did we evaluate different tools and choose KanbanTool in the end.</p>

<p>
The different tools we evaluated are:
<ul>
  <li><a href="http://leankit.com/">LeanKit</a></li>
  <li><a href="http://kanbanery.com/">Kanbanery</a></li>
  <li><a href="http://kanbantool.com/">KanbanTool</a></li>
</ul>
</p>


<p>
  We started off by comparing the features from the point of view of Kanban, but later realized that the features provided by Pivotal Tracker, especially the collaboration and tasks are very much important. Then we came up with a set of criteria which included both Kanban and non-Kanban requirements. You can see the criteria that we've used for evaluating the tool and our findings in <a href="https://docs.google.com/spreadsheet/ccc?key=0ApUPwJdQvqT_dEJuS25YZzMwWkJVc0NXWXhIbUhaQ1E&usp=sharing">this</a> document.
</p>


<p>
  <a href="https://trello.com/">Trello</a> was also considered but it does not provide features such as WIP limit, cycle and lead time reporting etc. which are the key for Kanban. But we found that there is a Google Chrome Extension which can be used for adding <a href="https://github.com/NateHark/TrelloWIPLimits">WIP(Work in Progress) limit</a> in Trello. And similarly other extensions exists too. But we felt its a very good tool which can used for <a href="http://en.wikipedia.org/wiki/Getting_Things_Done">GTD</a>, but may not be a good candidate as Kanban.
</p>


<p> Lastly, I would like to mention those articles which helped us to understand Kanban better. Those are:</p>

<ul>    
  <li><a href="http://www.agileproductdesign.com/blog/2009/kanban_over_simplified.html">Kanban Development OverSimplified</a> by Jeff Patton</li>
  <li><a href="http://www.infoq.com/presentations/Single-Piece-Flow-Kanban">Single Piece Workflow in Kanban</a> by James Shore and Arloo Banshee</li>
  <li><a href="http://www.crisp.se/gratis-material-och-guider/kanban">Kanban</a> by Henrik Kniberg</li>
</ul>



]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[AgileIndia 2013 Summary]]></title>
    <link href="http://www.multunus.com/2013/03/agileindia-2013-summary/"/>
    <updated>2013-03-08T17:07:00+05:30</updated>
    <id>http://www.multunus.com/2013/03/agileindia-2013-summary</id>
    <content type="html"><![CDATA[<p>This is the summary about the  recently concluded <a href="http://2013.agileindia.org/">Agile India Conference 2013</a>.
This gave me a chance to interact with great legends and leaders of software industry such as
Linda Rising, Mary Poppendieck, Henrik Kniberg, Jez Humble, Jeff Patton, Fred George, Craig Larman, Neil Ford, Venkat Subramaniam,
Aslam Khan, Karl Scotland, Kenji Hiranabe, Laurent Bossavit, Rebecca Parsons etc. and listen to them multiple times in the span of 4 days.  Amazing.</p>

<p>
  I am not going to write about each session I attended, am instead summarizing what I learned during those 4 days both by attending the sessions and by interacting with the speakers during those 4 days:
</p>


<ul>
    <li> Never stop learning. Experiment continuously. </li>
    <li> Experiments may fail, but learn from it and move on.</li>
  <li> Analyse why am I <i>doing</i> (whatever it is), and be innovative. If you delay innovation, it becomes worse.
  </li>
    <li>Great software can be created only with collaboration. So work as a team and share the responsibilities.</li>
    <li>Be a good coach rather being authoritative. This will help to implement changes effectively.</li>
  <li>Optimise the entire delivery process instead of just optimising the development process. Kanban helps to <i>optimise the whole</i> while Scrum helps to optimise only the development. </li>
    <li>Have tight feedback cycles by applying timeboxing mercilessly. This will help for continuous learning and improvement. Eg: 15 minutes TDD cycles which result in simple design with refactorings, Frequent Retrospectives etc.</li>
  <li>Apply Last Responsible Moment across, eg: Use practices such as <strong>Emergent Design</strong> and <strong>Evolutionary Architecture</strong> instead of doing <i>Big Design UpFront</i>. The Code complexity reports should help to identify the coding smells which helps to implement these practices.</li>
    <li>You can defer writing tests until the validation of feature is done. Adding acceptance tests for stability can deferred when you feel that it's time to have more stability</li>
</ul>


<p>
  Thanks a ton to Naresh Jain and team for organising such a wonderful event. Curious to know what's coming for Agile India 2014. :)
</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Introduction to Continuous Delivery]]></title>
    <link href="http://www.multunus.com/2012/05/introduction-to-continuous-delivery/"/>
    <updated>2012-05-15T14:49:16+05:30</updated>
    <id>http://www.multunus.com/2012/05/introduction-to-continuous-delivery</id>
    <content type="html"><![CDATA[<p>We've been doing Continuous Delivery for sometime and also been writing about how to implement the same. This post is about why Continuous Delivery is required and what problems does it solve.</p>

<h3><strong><span style="text-decoration: underline;">What is Continuous Delivery</span></strong></h3>


<p>Continuous Delivery is the process of being able to continuously deliver new versions of a software product to create a tight feedback loop between users and the project team—including the customer or product owner.</p>

<!-- more -->


<p>This helps to test new ideas and changes in the product and also measure the effect of changes in the revenue. Continuous Delivery means releasing software very frequently, i.e. multiple times a day, rather than once in months.</p>

<h3><strong>Bottlenecks for Continuous Delivery</strong></h3>


<div>Lets see the usual challenges for releases. The following are the challenges that we faced before moving to Continuous Delivery. Let me put it in this way i.e. the following are the challenges which got us thinking on how to make releases more predictable and pain free. We already had a Continuous Integration setup at our end, but that was not enough to ease the process.</div>


<ul>
    <li>No tracking on which version was deployed, when and to which environment</li>
    <li>Different people working on different branches, code merge hell when its ready for deployment.</li>
    <li>When an urgent bug needs to be fixed, the fix need to be replicated in multiple branches along with the mainline branch</li>
    <li>No easy way to revert back to the previous stable version</li>
</ul>


<p>We've seen even more challenges in teams which do not have a Continuous Integration setup yet. They are:</p>

<ul>
    <li>Adhoc build processes</li>
    <li>Too much time spent on manual testing</li>
    <li>Integration of code happens only during deployment</li>
    <li>Complexity of build and deployment increases, depending on the complexity of the app.</li>
    <li>For clustered environments, the deployment needs to be updated to all slaves</li>
</ul>


<div>

Thats when we stumbled upon "<a href="http://www.informit.com/store/product.aspx?isbn=0321601912&amp;WT.DCSext.w_ptgrevartcl=Continuous+Delivery%3a+Reliable+Software+Releases+through+Build%2c+Test%2c+and+Deployment+Automation_1641923_ISBNTopCover">Continuous Delivery</a>" book by Jez Humble and Dave Farley and extended our Continuous Integration setup to Continuous Delivery.

</div>


<div>
<h3>Continuous Delivery to the rescue</h3>
One of the key principle of Continuous Delivery is <strong>To </strong><strong>create a <em>repeatable</em> and <em>reliable</em> process for releasing software.</strong> It solves problems by providing fast automated feedback on the <strong>production readiness</strong> of the application - every time there is a change to the code, infrastructure or the configuration.  So in Continuous Delivery, <strong><em>Done </em>means <em>Released.</em></strong>

</div>


<div>A central pattern of Continuous Delivery is called the <em><strong>Deployment pipeline - </strong></em>an automated implementation of the application's build, deploy, test and release process. The following shows a sample deployment pipeline:</div>


<p style="text-align: center;"><img class="aligncenter" style="border: none;" src="https://s3.amazonaws.com/multunus-cdimages/pipeline.png" alt="Deployment Pipeline" width="549" height="189" /></p>




<div>The deployment pipeline includes the following build and deployment process:</div>


<ul>
    <li>Creates executable code to verify that the syntax of the source code is valid.</li>
    <li>Runs the unit tests to check that the code behaves as expected.</li>
    <li>Runs the acceptance tests to check that the application conforms to its business acceptance criteria—that it delivers the business value that was intended.</li>
    <li>Run nonfunctional tests which checks that the application performs sufficiently well in terms of capacity, availability, security, and so on to meet its users’ needs.</li>
    <li>Runs tools which check that the expected code quality criteria such as test coverage and other technology-specific metrics are met.</li>
    <li>Then in the manual testing environment, exploratory testing is done. In parallel a demonstration to the customer and a selection of users can also be done. This helps the product owner to decide whether there are missing features, or find bugs that require fixing.</li>
    <li>If any of the above fails, the deployment should be stopped because it is a clear indication that the application is not production ready.</li>
</ul>


<div>I will write about the Benefits of Continuous Delivery in the next post.</div>


<h4><span style="text-decoration: underline;">References</span></h4>


<div><a href="https://docs.google.com/a/multunus.com/present/edit?id=0AQj1177vtu0MZHRoM2dmN180NzRneGp2bXRndw">https://docs.google.com/a/multunus.com/present/edit?id=0AQj1177vtu0MZHRoM2dmN180NzRneGp2bXRndw</a></div>


<div><a href="http://www.informit.com/articles/article.aspx?p=1829417" target="_blank">http://www.informit.com/articles/article.aspx?p=1829417</a></div>


<div><a href="http://continousdelivery.com" target="_blank">http://continousdelivery.com</a></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Continuous Delivery for Android Apps – Part 2]]></title>
    <link href="http://www.multunus.com/2011/10/continuous-delivery-for-android-apps-part-2/"/>
    <updated>2011-10-06T06:51:57+05:30</updated>
    <id>http://www.multunus.com/2011/10/continuous-delivery-for-android-apps-part-2</id>
    <content type="html"><![CDATA[<p>This post talks about how to run tests for the build setup as mentioned in <a href="http://www.multunus.com/2011/09/continuous-delivery-for-android-apps-part-1/">Part 1</a>.</p>

<h3><span style="text-decoration: underline;">Generate the build script for test</span></h3>


<p>The suggested practice is to have 2 separate projects for android, one the source and the other for the tests. The following command will generate a build.xml for the test project. Replace the  with the path of the source path.</p>

<p><span style="font-family: Consolas, Monaco, 'Courier New', Courier, monospace; line-height: 18px;">android update test-project -m ../&lt;project-path&gt; -p . </span></p>

<p>One problem I've seen is that, it does not break the build even if there are failures in the test. Issue is reported here:</p>

<!-- more -->


<p><a href="http://code.google.com/p/android/issues/detail?id=14241">http://code.google.com/p/android/issues/detail?id=14241</a></p>

<p>I had to override the run-tests target as mentioned below to fix this issue:</p>

<pre>&lt;target name="run-tests" depends="-install-tested-project, install"
description="Runs tests from the package defined in test.package property"&gt;
    &lt;echo&gt;Running tests ...&lt;/echo&gt;
    &lt;exec executable="${adb}" failonerror="true" outputproperty="tests.output"&gt;
        &lt;arg value="shell" /&gt;
        &lt;arg value="am" /&gt;
        &lt;arg value="instrument" /&gt;
        &lt;arg value="-w" /&gt;
        &lt;arg value="-e" /&gt;
        &lt;arg value="coverage" /&gt;
        &lt;arg value="@{emma.enabled}" /&gt;
        &lt;arg value="${manifest.package}/${test.runner}" /&gt;
    &lt;/exec&gt;
    &lt;echo message="${tests.output}"/&gt;
    &lt;fail message="Tests failed!!!"&gt;
        &lt;condition&gt;
            &lt;or&gt;
            &lt;contains string="${tests.output}" substring="Error" /&gt;
            &lt;contains string="${tests.output}" substring="Fail" /&gt;
            &lt;/or&gt;
        &lt;/condition&gt;
     &lt;/fail&gt;
&lt;/target&gt;</pre>


<p>You can change the ant commands to <span style="font-family: Consolas, Monaco, 'Courier New', Courier, monospace; line-height: 18px;">clean run-tests release </span>in Jenkins to run the tests as part of packaging.</p>

<p>Next I will be writing about how to start emulator from Jenkins while running the tests.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Confident Estimates]]></title>
    <link href="http://www.multunus.com/2011/09/confident-estimates/"/>
    <updated>2011-09-29T08:58:51+05:30</updated>
    <id>http://www.multunus.com/2011/09/confident-estimates</id>
    <content type="html"><![CDATA[<div class="zemanta-img" style="margin: 1em; display: block;">

<a href="http://commons.wikipedia.org/wiki/File:Goudargues.JPG"><img title="Goudargues" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Goudargues.JPG/300px-Goudargues.JPG" alt="Goudargues" width="300" height="200" /></a>

</div>


<p>We constantly try to provide accurate estimates that we can defend with confidence. But there are situations where we end up making mistakes. And this post describes one such situation.</p>

<!-- more -->


<p>One of our clients asked us to estimate a feature. As usual, we sent back an estimate without much delay.</p>

<p>After few days, our client asked us to implement this feature. When we started to think about implementing the feature we found that it would take at least double the time that we'd earlier estimated. We'd put ourselves in a bad situation. It would of course be very hard to convince the client as to why there was this much deviation - considering we discovered this even before actually starting to implement the feature. We did the 5 why's to get to the root of the problem.</p>

<p>We discovered the following reasons:</p>

<ul>
    <li>We hadn't gone through the usual process of breaking down the feature to the desired level of granularity. Digging deeper, the following root causes emerged:
<ul>
    <li>The project had been on 'pause' mode for a couple of weeks and we had gotten busy with other things in the meanwhile.</li>
    <li>The value of the feature [to the end user] was not completely obvious to us.</li>
</ul>
</li>
</ul>


<p>The solution? We've decided to ask ourselves the following question before sending across an estimate to any client in the future:</p>

<blockquote><em>Is this a <strong>confident estimate</strong>? Can we defend the estimate with proper reasoning?</em></blockquote>


<p>The above will force us to think again about the estimate and help us become more consistent.</p>

<p><strong><span style="color: #008000;">Oh, and one more thing</span></strong>. Ask the stakeholder as to what value the feature is going to add - if it is not obvious. Don't assume that you're right!</p>

<p>If you're curious on what the client's reaction was, when we sent across the revised [and much larger] estimate, <strong>ask us in the comment below</strong> :) We'd love to hear from you!</p>

<p><span style="color: #008000;"><strong>
</strong></span></p>
]]></content>
  </entry>
  
</feed>
